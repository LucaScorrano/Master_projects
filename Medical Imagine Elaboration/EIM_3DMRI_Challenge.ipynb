{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXM6hEUszAK5BlZosHrqKE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# EIM 2022-2023: Agresti, Manzi, Scorrano, Serracca"],"metadata":{"id":"QiFJPlaD19kC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNbRWdX2z6A4"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install light-the-torch && ltt install torch\n","!pip install torchio\n","!pip install SimpleITK\n","!pip install itk"],"metadata":{"id":"x01cExbo0KAB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Import librerie"],"metadata":{"id":"iTgD_6Hq0OqA"}},{"cell_type":"code","source":["import os\n","import SimpleITK as sitk\n","import nibabel as nib\n","from tqdm import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import shutil\n","import random\n","import PIL\n","\n","#------- Installazione Librerie Mancanti #-------\n","!pip install tensorflow\n","!python3 -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n","\n","#------- Librerie Skimage -------------\n","import skimage\n","import skimage.io as img\n","import skimage.transform as transform\n","from skimage.transform import rotate\n","from skimage.restoration import denoise_tv_chambolle\n","from skimage import img_as_float, img_as_ubyte\n","from skimage import exposure\n","\n","#------- Librerie Monai -------------\n","import monai\n","from monai.metrics import DiceMetric\n","from monai.inferers import SimpleInferer\n","from monai.transforms import (\n","    ShiftIntensity,\n","    AsDiscrete,\n","    SpatialPad,\n","    RandZoom,\n","    DataStatsd,\n","    HistogramNormalized,\n","    CenterSpatialCrop,\n","    AddChanneld,\n","    Rotated,\n","    BatchInverseTransform,\n","    HistogramNormalize,\n","    RandZoom,\n","    RandHistogramShiftd,\n","    Rand2DElasticd,\n","    CenterSpatialCropd,\n","    RandSmoothFieldAdjustContrast,\n","    Compose,\n","    RandScaleCrop,\n","    RandSpatialCropd,\n","    EnsureTyped,\n","    Activations,\n","    LoadImaged,\n","    Affine,\n","    Resized,\n","    Spacingd,\n","    RandAffined,\n","    RandFlipd,\n","    EnsureChannelFirst,\n","    ScaleIntensityRanged,\n","    Activationsd,\n","    AsDiscreted,\n","    FillHoles,\n","    KeepLargestConnectedComponent,\n","    DataStats,\n","    AsChannelFirstd,\n","    AsDiscreted,\n","    ToTensord,\n","    EnsureType,\n","    CropForegroundd,\n","    RandAdjustContrastd,\n","    Orientationd,\n","    SqueezeDimd,\n","    RandGaussianNoised,\n","    RandRotated,\n","    Zoomd,\n","    GibbsNoised,\n","    KSpaceSpikeNoised,\n","    AdjustContrastd\n","    )\n","from monai.data import (\n","    DataLoader,\n","    Dataset,\n","    CacheDataset,\n","    PILReader,\n","    IterableDataset,\n","    decollate_batch)\n","from monai.utils import set_determinism, first\n","from monai.config import print_config\n","from monai.networks.nets import UNet, SegResNet\n","from monai.networks.layers import Norm\n","from monai.transforms.spatial.dictionary import RandZoomd\n","\n","#------- Altre Librerie -------------\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm.auto import tqdm\n","import torch\n","import PIL\n","import cv2\n","import torchio as tio\n","from scipy import ndimage\n","from scipy.signal import medfilt2d\n","from scipy.ndimage import binary_fill_holes\n","from scipy.spatial import distance\n","from scipy.spatial.distance import directed_hausdorff\n","import plotly.express as px\n","import math\n","import itk as it\n","import tensorflow as tf"],"metadata":{"id":"igkc4brs0ORr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Estrazione immagini"],"metadata":{"id":"rtJD2lqP0XTU"}},{"cell_type":"code","source":["!unzip \"/content/drive/MyDrive/Colab Notebooks/3DMRI Challenge/mm3DMRI.zip\""],"metadata":{"id":"sQJ-baYX0Vce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ESTRAZIONE IMMAGINI TRAINING SET\n","\n","main = '/content'\n","dataFolder = os.path.join(main, 'DATASET','VOLUMES','TRAIN')\n","outputFolder = os.path.join(main, 'DATASET','SLICES')\n","if not os.path.isdir(outputFolder):\n","      os.mkdir(outputFolder)\n","\n","volumesList = os.listdir(dataFolder)\n","\n","for i in tqdm(volumesList):\n","\n","    subjectFolder = os.path.join(dataFolder, i)\n","    subjectOuputFolder = os.path.join(outputFolder, i)\n","\n","    if not os.path.isdir(subjectOuputFolder):\n","      os.mkdir(subjectOuputFolder)\n","\n","    if not '.DS_Store' in subjectFolder:\n","\n","        files = [x for x in os.listdir(subjectFolder)]\n","\n","        slicesToTake =  range(30,120,5) # Vengono selezionate le slices multiple di 5 dalla 30 alla 119\n","\n","        for j in files:\n","\n","            if 'seg' in  j:\n","\n","                vol_file = os.path.join(subjectFolder,j)\n","\n","                inputVolume = sitk.ReadImage(vol_file)\n","                numpyVolume = sitk.GetArrayFromImage(inputVolume).astype(np.uint8)>0\n","\n","                sliceOutputFolder = os.path.join(subjectOuputFolder,j.split('_')[1].split('.')[0])\n","\n","                if not os.path.isdir(sliceOutputFolder):\n","                    os.mkdir(sliceOutputFolder)\n","\n","                for k in  slicesToTake:\n","\n","                    filename = os.path.join(sliceOutputFolder, '{:04d}.png'.format(k))\n","                    tempSlice = numpyVolume[k,:,:].astype(np.uint8)*255\n","                    slicePIL = PIL.Image.fromarray(tempSlice,mode='L')\n","                    slicePIL.save(filename)\n","\n","            else:\n","\n","                vol_file = os.path.join(subjectFolder,j)\n","\n","                inputVolume = sitk.ReadImage(vol_file)\n","                numpyVolume = sitk.GetArrayFromImage(inputVolume)\n","\n","                numpyVolume = numpyVolume/np.max(numpyVolume)*255 # normalizzazione\n","                numpyVolume = numpyVolume.astype(np.uint8)\n","\n","                sliceOutputFolder = os.path.join(subjectOuputFolder,j.split('_')[1].split('.')[0])\n","\n","                if not os.path.isdir(sliceOutputFolder):\n","                    os.mkdir(sliceOutputFolder)\n","\n","                for k in  slicesToTake:\n","\n","                    filename = os.path.join(sliceOutputFolder, '{:04d}.png'.format(k))\n","                    tempSlice = numpyVolume[k,:,:]\n","                    slicePIL = PIL.Image.fromarray(tempSlice,mode='L')\n","                    slicePIL.save(filename)"],"metadata":{"id":"iTP04dLW0dNc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ESTRAZIONE IMMAGINI VALIDATION\n","\n","main = '/content/'\n","dataFolder = os.path.join(main, 'DATASET','VOLUMES','VALIDATION')\n","outputFolder = os.path.join(main + 'DATASET','SLICES_VALIDATION')\n","if not os.path.isdir(outputFolder):\n","      os.mkdir(outputFolder)\n","\n","volumesList = os.listdir(dataFolder)\n","\n","for i in tqdm(volumesList):\n","\n","    subjectFolder = os.path.join(dataFolder, i)\n","    subjectOuputFolder = os.path.join(outputFolder, i)\n","\n","    if not os.path.isdir(subjectOuputFolder):\n","      os.mkdir(subjectOuputFolder)\n","\n","    if not '.DS_Store' in subjectFolder:\n","\n","        files = [x for x in os.listdir(subjectFolder)]\n","\n","        slicesToTake =  range(30,120,3) # Viene selezionata una slice ogni 3 dalla 30 alla 120\n","\n","        for j in files:\n","\n","            if 'seg' in  j:\n","\n","                vol_file = os.path.join(subjectFolder,j)\n","\n","                inputVolume = sitk.ReadImage(vol_file)\n","                numpyVolume = sitk.GetArrayFromImage(inputVolume).astype(np.uint8)>0\n","\n","                sliceOutputFolder = os.path.join(subjectOuputFolder,j.split('_')[1].split('.')[0])\n","\n","                if not os.path.isdir(sliceOutputFolder):\n","                    os.mkdir(sliceOutputFolder)\n","\n","                for k in  slicesToTake:\n","\n","                    filename = os.path.join(sliceOutputFolder, '{:04d}.png'.format(k))\n","                    tempSlice = numpyVolume[k,:,:].astype(np.uint8)*255\n","                    slicePIL = PIL.Image.fromarray(tempSlice,mode='L')\n","                    slicePIL.save(filename)\n","\n","            else:\n","\n","                vol_file = os.path.join(subjectFolder,j)\n","\n","                inputVolume = sitk.ReadImage(vol_file)\n","                numpyVolume = sitk.GetArrayFromImage(inputVolume)\n","\n","                numpyVolume = numpyVolume/np.max(numpyVolume)*255 # normalizzazione\n","                numpyVolume = numpyVolume.astype(np.uint8)\n","\n","                sliceOutputFolder = os.path.join(subjectOuputFolder,j.split('_')[1].split('.')[0])\n","\n","                if not os.path.isdir(sliceOutputFolder):\n","                    os.mkdir(sliceOutputFolder)\n","\n","                for k in  slicesToTake:\n","\n","                    filename = os.path.join(sliceOutputFolder, '{:04d}.png'.format(k))\n","                    tempSlice = numpyVolume[k,:,:]\n","                    slicePIL = PIL.Image.fromarray(tempSlice,mode='L')\n","                    slicePIL.save(filename)\n"],"metadata":{"id":"Elsnttdf0fZ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ESTRAZIONE IMMAGINI TRAINING_AUGMENTED\n","\n","main = '/content'\n","dataFolder = os.path.join(main, 'DATASET','VOLUMES','TRAIN')\n","outputFolder = os.path.join(main, 'DATASET','SLICES_AUGMENTED')\n","if not os.path.isdir(outputFolder):\n","      os.mkdir(outputFolder)\n","\n","volumesList = os.listdir(dataFolder)\n","\n","for i in tqdm(volumesList):\n","\n","    subjectFolder = os.path.join(dataFolder, i)\n","    subjectOuputFolder = os.path.join(outputFolder, i)\n","\n","    if not os.path.isdir(subjectOuputFolder):\n","      os.mkdir(subjectOuputFolder)\n","\n","    if not '.DS_Store' in subjectFolder:\n","\n","        files = [x for x in os.listdir(subjectFolder)]\n","\n","        slicesToTake =  range(37,112,5) # viene selezionata una slice ogni 5 dalla 37 alla 112\n","\n","        for j in files:\n","\n","            if 'seg' in  j:\n","\n","                vol_file = os.path.join(subjectFolder,j)\n","\n","                inputVolume = sitk.ReadImage(vol_file)\n","                numpyVolume = sitk.GetArrayFromImage(inputVolume).astype(np.uint8)>0\n","\n","                sliceOutputFolder = os.path.join(subjectOuputFolder,j.split('_')[1].split('.')[0])\n","\n","                if not os.path.isdir(sliceOutputFolder):\n","                    os.mkdir(sliceOutputFolder)\n","\n","                for k in  slicesToTake:\n","\n","                    filename = os.path.join(sliceOutputFolder, '{:04d}.png'.format(k))\n","                    tempSlice = numpyVolume[k,:,:].astype(np.uint8)*255\n","                    slicePIL = PIL.Image.fromarray(tempSlice,mode='L')\n","                    slicePIL.save(filename)\n","\n","            else:\n","\n","                vol_file = os.path.join(subjectFolder,j)\n","\n","                inputVolume = sitk.ReadImage(vol_file)\n","                numpyVolume = sitk.GetArrayFromImage(inputVolume)\n","\n","                numpyVolume = numpyVolume/np.max(numpyVolume)*255 # normalizzazione\n","                numpyVolume = numpyVolume.astype(np.uint8)\n","\n","                sliceOutputFolder = os.path.join(subjectOuputFolder,j.split('_')[1].split('.')[0])\n","\n","                if not os.path.isdir(sliceOutputFolder):\n","                    os.mkdir(sliceOutputFolder)\n","\n","                for k in  slicesToTake:\n","\n","                    filename = os.path.join(sliceOutputFolder, '{:04d}.png'.format(k))\n","                    tempSlice = numpyVolume[k,:,:]\n","                    slicePIL = PIL.Image.fromarray(tempSlice,mode='L')\n","                    slicePIL.save(filename)"],"metadata":{"id":"Ej7moX2S0k--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! rm -r '/content/DATASET/TRAIN_IMG'\n","! rm -r '/content/DATASET/VAL_IMG'\n","! rm -r '/content/DATASET/TEST_IMG'\n","! rm -r '/content/DATASET/TRAIN_AUGM_IMG'"],"metadata":{"id":"2wL-N11T0n1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creazione path per preparzazione del dataset\n","\n","current_dir = '/content/DATASET'\n","testFd_tr = os.path.join(current_dir,'TRAIN_IMG')\n","testFd_val = os.path.join(current_dir,'VAL_IMG')\n","testFd_test = os.path.join(current_dir,'TEST_IMG')\n","testFd_tr_augm = os.path.join(current_dir,'TRAIN_AUGM_IMG')\n","if not os.path.isdir(testFd_tr):\n","    os.mkdir(testFd_tr),\n","    os.mkdir(testFd_val),\n","    os.mkdir(testFd_test)\n","    os.mkdir(testFd_tr_augm)\n"],"metadata":{"id":"i0CH1V500raZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def kernel_gauss(size, sigma):\n","  v = np.linspace(-(size-1)/2,(size-1)/2,size)\n","  x, y = np.meshgrid(v,v)\n","  h = np.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n","  h = h/h.sum()\n","  return h"],"metadata":{"id":"_c4s6gcX0uJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def normalize8(I):\n","  mn = I.min()\n","  mx = I.max()\n","\n","  mx -= mn\n","\n","  I = ((I - mn)/mx) * 255\n","  return I.astype(np.uint8)"],"metadata":{"id":"xih13MTX0wqq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_name = '/content/DATASET'\n","#estraggo le immagini in T1\n","SLICES_path = os.path.join(dataset_name,'SLICES')\n","SLICES_VAL_path = os.path.join(dataset_name,'SLICES_VALIDATION')\n","SLICE_AUGM_path = os.path.join(dataset_name,'SLICES_AUGMENTED')\n","\n","images = os.listdir(SLICES_path)\n","images = sorted(images)\n","val_images = os.listdir(SLICES_VAL_path)\n","augm_img = os.listdir(SLICE_AUGM_path)\n","\n","#SUDDIVISIONE DEL TRAINING DATA E DEL TEST DATA\n","#la quantità di immagini è pari a:\n","num_img = len(images)\n","#ripartisco le immagini in 80% training e 20% Test (Le immagini per il validation sono già fornite)\n","num_train = int(round(num_img*0.8))\n","num_test = int(num_img - num_train)\n","#Estraggo le immagini del training e del test\n","train_images = images[0:num_train]\n","test_images = images[num_train:]\n","\n","elenco = images\n","beta = 255  # max valore del pixel con codifica uint8\n","size = 5    # dimensione del kernel del filtro gaussiano\n","sigma = 0.5 # sigma del filtro gaussiano\n","h = kernel_gauss(size, sigma) # creazione del kernel del filtro gaussiano\n","toll = 1e-4 # tolleranza\n","\n","\n","training_data_t1 = []\n","# preparazione immagini \"RGB\" training\n","for i in train_images:\n","  path_temp = os.path.join(SLICES_path,i)\n","  if not os.path.isdir(testFd_tr + '/' + i):\n","    os.mkdir(testFd_tr + '/' + i),\n","  for j in os.listdir(path_temp + '/seg'):\n","    t1 = cv2.imread((os.path.join(SLICES_path, i,'t1',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t1_eq = exposure.equalize_adapthist(t1, nbins=255)\n","    t1_norm = normalize8(t1_eq)\n","\n","    t1ce = cv2.imread((os.path.join(SLICES_path, i,'t1ce',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t1ce_eq = exposure.equalize_adapthist(t1ce, nbins=255)\n","    t1ce_norm = normalize8(t1ce_eq)\n","\n","    t2 = cv2.imread((os.path.join(SLICES_path, i,'t2',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t2_eq = exposure.equalize_adapthist(t2, nbins=255)\n","    t2_norm = normalize8(t2_eq)\n","\n","    seg = cv2.imread((os.path.join(SLICES_path, i,'seg',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","\n","    image_to_save = np.stack([t1_norm,t1ce_norm,t2_norm], axis=2)\n","    image_to_save = np.squeeze(image_to_save)\n","\n","    pz_path = os.path.join(testFd_tr,i);\n","    path_img_save = os.path.join(pz_path,'img');\n","    path_seg_save = os.path.join(pz_path,'seg')\n","    if not os.path.isdir(pz_path):\n","      os.mkdir(pz_path)\n","    if not os.path.isdir(path_img_save):\n","      os.mkdir(path_img_save)\n","      os.mkdir(path_seg_save)\n","    img.imsave(os.path.join(path_img_save,j), image_to_save)\n","    img.imsave(os.path.join(path_seg_save,j), seg)\n","\n","\n","# preparazione immagini \"RGB\" test\n","for i in test_images:\n","  path_temp = os.path.join(SLICES_path,i)\n","  if not os.path.isdir(testFd_test + '/' + i):\n","    os.mkdir(testFd_test + '/' + i),\n","  for j in os.listdir(path_temp + '/seg'):\n","    t1 = cv2.imread((os.path.join(SLICES_path, i,'t1',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t1_eq = exposure.equalize_adapthist(t1, nbins=255)\n","    x1, y1, x2, y2 = 0, 0, 30, 30\n","    t1_background_1 = np.array(t1_eq[y1:y2, x1:x2])\n","    std_dev_1 = np.std(t1_background_1)\n","    x1, y1, x2, y2 = 0, 170, 30, 200\n","    t1_background_2 = np.array(t1_eq[y1:y2, x1:x2])\n","    std_dev_2 = np.std(t1_background_2)\n","    x1, y1, x2, y2 = 170, 0, 200, 30\n","    t1_background_3 = np.array(t1_eq[y1:y2, x1:x2])\n","    std_dev_3 = np.std(t1_background_3)\n","    x1, y1, x2, y2 = 170, 170, 200, 200\n","    t1_background_4 = np.array(t1_eq[y1:y2, x1:x2])\n","    std_dev_4 = np.std(t1_background_4)\n","    std_dev_t1 = np.max(np.array([std_dev_1,std_dev_2,std_dev_3,std_dev_4]))\n","    if not math.isclose(std_dev_t1, 0, abs_tol=toll):\n","      print(\"applicato filtro gaussiano all'immagine t1: paziente->\", i, \" immagine->\", j)\n","      print(\"deviazione standard = \", std_dev_t1)\n","      t1_gauss = ndimage.correlate(t1_eq,h)\n","      t1_eq = t1_gauss\n","    t1_gibbs = denoise_tv_chambolle(t1_eq, weight=0.01)\n","    t1_norm = normalize8(t1_gibbs)\n","\n","    t1ce = cv2.imread((os.path.join(SLICES_path, i,'t1ce',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t1ce_eq = exposure.equalize_adapthist(t1ce, nbins=255)\n","    x1, y1, x2, y2 = 0, 0, 30, 30\n","    t1ce_background_1 = np.array(t1ce_eq[y1:y2, x1:x2])\n","    std_dev_1 = np.std(t1_background_1)\n","    x1, y1, x2, y2 = 0, 170, 30, 200\n","    t1ce_background_2 = np.array(t1ce_eq[y1:y2, x1:x2])\n","    std_dev_2 = np.std(t1_background_2)\n","    x1, y1, x2, y2 = 170, 0, 200, 30\n","    t1ce_background_3 = np.array(t1ce_eq[y1:y2, x1:x2])\n","    std_dev_3 = np.std(t1_background_3)\n","    x1, y1, x2, y2 = 170, 170, 200, 200\n","    t1ce_background_4 = np.array(t1ce_eq[y1:y2, x1:x2])\n","    std_dev_4 = np.std(t1_background_4)\n","    std_dev_t1ce = np.max(np.array([std_dev_1,std_dev_2,std_dev_3,std_dev_4]))\n","    if not math.isclose(std_dev_t1ce, 0, abs_tol=toll):\n","      print(\"applicato filtro gaussiano all'immagine t1ce: paziente->\", i, \" immagine->\", j)\n","      print(\"deviazione standard = \", std_dev_t1ce)\n","      t1ce_gauss = ndimage.correlate(t1ce_eq,h)\n","      t1ce_eq = t1ce_gauss\n","    t1ce_gibbs = denoise_tv_chambolle(t1ce_eq, weight=0.01)\n","    t1ce_norm = normalize8(t1ce_gibbs)\n","\n","\n","    t2 = cv2.imread((os.path.join(SLICES_path, i,'t2',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t2_eq = exposure.equalize_adapthist(t2, nbins=255)\n","    x1, y1, x2, y2 = 0, 0, 30, 30\n","    t2_background_1 = np.array(t2_eq[y1:y2, x1:x2])\n","    std_dev_1 = np.std(t1_background_1)\n","    x1, y1, x2, y2 = 0, 170, 30, 200\n","    t2_background_2 = np.array(t2_eq[y1:y2, x1:x2])\n","    std_dev_2 = np.std(t1_background_2)\n","    x1, y1, x2, y2 = 170, 0, 200, 30\n","    t2_background_3 = np.array(t2_eq[y1:y2, x1:x2])\n","    std_dev_3 = np.std(t1_background_3)\n","    x1, y1, x2, y2 = 170, 170, 200, 200\n","    t2_background_4 = np.array(t2_eq[y1:y2, x1:x2])\n","    std_dev_4 = np.std(t1_background_4)\n","    std_dev_t2 = np.max(np.array([std_dev_1,std_dev_2,std_dev_3,std_dev_4]))\n","    if not math.isclose(std_dev_t2, 0, abs_tol=toll):\n","      print(\"applicato filtro gaussiano all'immagine t2: paziente->\", i, \" immagine->\", j)\n","      print(\"deviazione standard = \", std_dev_t2)\n","      t2_gauss = ndimage.correlate(t2_eq,h)\n","      t2_eq = t2_gauss\n","    t2_gibbs = denoise_tv_chambolle(t2_eq, weight=0.01)\n","    t2_norm = normalize8(t2_gibbs)\n","\n","\n","    seg = cv2.imread((os.path.join(SLICES_path, i,'seg',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","\n","    image_to_save = np.stack([t1_norm,t1ce_norm,t2_norm], axis=2)\n","    image_to_save = np.squeeze(image_to_save)\n","\n","    pz_path = os.path.join(testFd_test,i);\n","    path_img_save = os.path.join(pz_path,'img');\n","    path_seg_save = os.path.join(pz_path,'seg')\n","    if not os.path.isdir(pz_path):\n","      os.mkdir(pz_path)\n","    if not os.path.isdir(path_img_save):\n","      os.mkdir(path_img_save)\n","      os.mkdir(path_seg_save)\n","    img.imsave(os.path.join(path_img_save,j), image_to_save)\n","    img.imsave(os.path.join(path_seg_save,j), seg)\n","\n","\n","# preparazione immagini \"RGB\" validation\n","testFd_val = os.path.join(current_dir,'VAL_IMG')\n","for i in os.listdir(SLICES_VAL_path):\n","  path_temp = os.path.join(SLICES_VAL_path,i)\n","  if not os.path.isdir(testFd_val + '/' + i):\n","    os.mkdir(testFd_val + '/' + i),\n","  for j in os.listdir(path_temp + '/seg'):\n","    t1 = cv2.imread((os.path.join(SLICES_VAL_path, i,'t1',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t1_eq = exposure.equalize_adapthist(t1, nbins=255)\n","    t1_norm = normalize8(t1_eq)\n","\n","    t1ce = cv2.imread((os.path.join(SLICES_VAL_path, i,'t1ce',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t1ce_eq = exposure.equalize_adapthist(t1ce, nbins=255)\n","    t1ce_norm = normalize8(t1ce_eq)\n","\n","    t2 = cv2.imread((os.path.join(SLICES_VAL_path, i,'t2',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t2_eq = exposure.equalize_adapthist(t2, nbins=255)\n","    t2_norm = normalize8(t2_eq)\n","\n","    seg = cv2.imread((os.path.join(SLICES_VAL_path, i,'seg',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","\n","    image_to_save = np.stack([t1_norm,t1ce_norm,t2_norm], axis=2)\n","    image_to_save = np.squeeze(image_to_save)\n","\n","    pz_path = os.path.join(testFd_val,i);\n","    path_img_save = os.path.join(pz_path,'img');\n","    path_seg_save = os.path.join(pz_path,'seg')\n","    if not os.path.isdir(pz_path):\n","      os.mkdir(pz_path)\n","    if not os.path.isdir(path_img_save):\n","      os.mkdir(path_img_save)\n","      os.mkdir(path_seg_save)\n","    img.imsave(os.path.join(path_img_save,j), image_to_save)\n","    img.imsave(os.path.join(path_seg_save,j), seg)\n","\n","\n","# preparazione immagini \"RGB\" training_augmented (data augmenting)\n","testFd_augm = os.path.join(current_dir,'TRAIN_AUGM_IMG')\n","for i in os.listdir(SLICE_AUGM_path):\n","  path_temp = os.path.join(SLICE_AUGM_path,i)\n","  if not os.path.isdir(testFd_augm + '/' + i):\n","    os.mkdir(testFd_augm + '/' + i),\n","  for j in os.listdir(path_temp + '/seg'):\n","    t1 = cv2.imread((os.path.join(SLICE_AUGM_path, i,'t1',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t1_eq = exposure.equalize_adapthist(t1, nbins=255)\n","    t1_norm = normalize8(t1_eq)\n","\n","\n","    t1ce = cv2.imread((os.path.join(SLICE_AUGM_path, i,'t1ce',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t1ce_eq = exposure.equalize_adapthist(t1ce, nbins=255)\n","    t1ce_norm = normalize8(t1ce_eq)\n","\n","\n","    t2 = cv2.imread((os.path.join(SLICE_AUGM_path, i,'t2',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","    t2_eq = exposure.equalize_adapthist(t2, nbins=255)\n","    t2_norm = normalize8(t2_eq)\n","\n","    seg = cv2.imread((os.path.join(SLICE_AUGM_path, i,'seg',j)),cv2.IMREAD_GRAYSCALE)[20:220,20:220];\n","\n","    image_to_save = np.stack([t1_norm,t1ce_norm,t2_norm], axis=2)\n","    image_to_save = np.squeeze(image_to_save)\n","\n","    pz_path = os.path.join(testFd_augm,i);\n","    path_img_save = os.path.join(pz_path,'img');\n","    path_seg_save = os.path.join(pz_path,'seg')\n","    if not os.path.isdir(pz_path):\n","      os.mkdir(pz_path)\n","    if not os.path.isdir(path_img_save):\n","      os.mkdir(path_img_save)\n","      os.mkdir(path_seg_save)\n","    img.imsave(os.path.join(path_img_save,j), image_to_save)\n","    img.imsave(os.path.join(path_seg_save,j), seg)\n"],"metadata":{"id":"G2fQLdMQ0ykB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creazione dei path e dei dizionari per le cartelle in cui sono contenuti training set, training set augmented, test set e validation set\n","train_path = '/content/DATASET/TRAIN_IMG'\n","training_data = []\n","for i in train_images:\n","  path_temp = os.path.join(train_path,i,\"seg\")\n","  for j in os.listdir(path_temp):\n","    tempDict = {'image': os.path.join(train_path,i,\"img\",j),'segmentation': os.path.join(train_path, i,'seg',j)}\n","    training_data.append(tempDict)\n","\n","train_augm_path = '/content/DATASET/TRAIN_AUGM_IMG'\n","training_augm_data = []\n","for i in augm_img:\n","  path_temp = os.path.join(train_augm_path,i,\"seg\")\n","  for j in os.listdir(path_temp):\n","    tempDict = {'image': os.path.join(train_augm_path,i,\"img\",j),'segmentation': os.path.join(train_augm_path, i,'seg',j)}\n","    training_augm_data.append(tempDict)\n","\n","test_path = '/content/DATASET/TEST_IMG'\n","test_data = []\n","for i in test_images:\n","  path_temp = os.path.join(test_path,i,\"seg\")\n","  for j in os.listdir(path_temp):\n","    tempDict = {'image': os.path.join(test_path, i,\"img\",j),'segmentation': os.path.join(test_path, i,'seg',j)}\n","    test_data.append(tempDict)\n","\n","val_path = '/content/DATASET/VAL_IMG'\n","validation_data = []\n","for i in os.listdir(SLICES_VAL_path):\n","  path_temp = os.path.join(val_path,i,\"seg\")\n","  for j in os.listdir(path_temp):\n","    tempDict = {'image': os.path.join(val_path, i,\"img\",j),'segmentation': os.path.join(val_path, i,'seg',j)}\n","    validation_data.append(tempDict)"],"metadata":{"id":"VPMv4fH600kp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prova di visualizzazione immagine\n","immagine_prova = img.imread(\"/content/DATASET/TRAIN_IMG/00001/seg/0045.png\")\n","fig = px.imshow(immagine_prova,color_continuous_scale='gray')\n","fig.show()\n","dimension = np.shape(immagine_prova)\n","print(dimension)"],"metadata":{"id":"9A6IFeVJ02iy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inizializzazione parametri modello\n","ROI_SIZE = [(200),(200)]  # dimensioni immagine da fornire alla rete\n","ROI_SIZE_RAND = [100,100] # valore utile per un'operazione di data augmentation successiva\n","BATCH_SIZE = 72\n","wks = 0"],"metadata":{"id":"-xtKOrda04-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TRAINING + DATA AUGMENTATION: TRASFORMAZIONI, DATASET e DATALOADER\n","train_transforms_0 = Compose(\n","       [LoadImaged(keys=[\"image\",\"segmentation\"],image_only=False,reader=PILReader()), # caricamento dell'immagine\n","        AsChannelFirstd(keys=[\"image\"]),\n","        AddChanneld(keys=[\"segmentation\"]), # portare l'immagine nel formato channel-first (canali, dimensione 0, dimensione 1)\n","        Resized(keys=[\"image\", \"segmentation\"], spatial_size=ROI_SIZE, mode = \"area\"),\n","        ScaleIntensityRanged(keys=[\"image\", \"segmentation\"],a_min=0,a_max=255,b_min=0.0,b_max=1.0,clip=True), # riscala i valori all'interno dell'immagine e della segmentazione dal range 0-255 al range 0-1\n","        AdjustContrastd(keys = ['image'], gamma = 1.5),\n","        AsDiscreted(keys=[\"segmentation\"],threshold=0.5), # porta la segmentazione in formato binario con soglia 0.5 (abbiamo modificato il range di valori nella trasformazione precedente),\n","        ToTensord(keys=[\"image\", \"segmentation\"])])\n","\n","#rumore gaussiano + rotazione\n","train_transforms_1 = Compose(\n","        [LoadImaged(keys=[\"image\",\"segmentation\"],image_only=False,reader=PILReader(), flag = 'gray'), # caricamento dell'immagine\n","        AsChannelFirstd(keys=[\"image\"]),\n","        AddChanneld(keys=[\"segmentation\"]), # portare l'immagine nel formato channel-first (canali, dimensione 0, dimensione 1)\n","        CenterSpatialCropd(keys=[\"image\",\"segmentation\"], roi_size = ROI_SIZE_RAND),\n","        Resized(keys=[\"image\", \"segmentation\"], spatial_size=ROI_SIZE, mode = \"area\"),\n","        ScaleIntensityRanged(keys=[\"image\", \"segmentation\"],a_min=0,a_max=255,b_min=0.0,b_max=1.0,clip=True), # riscala i valori all'interno dell'immagine e della segmentazione dal range 0-255 al range 0-1\n","        AdjustContrastd(keys = ['image'], gamma = 1.5),\n","        AsDiscreted(keys=[\"segmentation\"],threshold=0.5), # porta la segmentazione in formato binario con soglia 0.5 (abbiamo modificato il range di valori nella trasformazione precedente)\n","        RandGaussianNoised(keys=\"image\",mean=0,std=0.1,prob=1),\n","        RandRotated(keys=[\"image\", \"segmentation\"],prob=0.1,range_x=10.0,padding_mode=\"zeros\"),\n","        ToTensord(keys=[\"image\", \"segmentation\"])])\n","\n","#rumore di Gibbs + randomflip\n","train_transforms_2 = Compose(\n","       [LoadImaged(keys=[\"image\",\"segmentation\"],image_only=False,reader=PILReader(), flag = 'gray'), # caricamento dell'immagine\n","        AsChannelFirstd(keys=[\"image\"]),\n","        AddChanneld(keys=[\"segmentation\"]), # portare l'immagine nel formato channel-first (canali, dimensione 0, dimensione 1)\n","        Resized(keys=[\"image\", \"segmentation\"], spatial_size=ROI_SIZE, mode = \"area\"),\n","        ScaleIntensityRanged(keys=[\"image\", \"segmentation\"],a_min=0,a_max=255,b_min=0.0,b_max=1.0,clip=True), # riscala i valori all'interno dell'immagine e della segmentazione dal range 0-255 al range 0-1\n","        AdjustContrastd(keys = ['image'], gamma = 1.5),\n","        AsDiscreted(keys=[\"segmentation\"],threshold=0.5), # porta la segmentazione in formato binario con soglia 0.5 (abbiamo modificato il range di valori nella trasformazione precedente)\n","        RandFlipd(keys=[\"image\", \"segmentation\"],spatial_axis=[0],prob=1),\n","        GibbsNoised(keys=[\"image\"], alpha=0.8),\n","        ToTensord(keys=[\"image\", \"segmentation\"])])\n","\n","# KSpaceSpikeNoised + zoomd\n","train_transforms_3 = Compose(\n","       [LoadImaged(keys=[\"image\",\"segmentation\"],image_only=False,reader=PILReader(), flag = 'gray'), # caricamento dell'immagine\n","        AsChannelFirstd(keys=[\"image\"]),\n","        AddChanneld(keys=[\"segmentation\"]), # portare l'immagine nel formato channel-first (canali, dimensione 0, dimensione 1)\n","        Resized(keys=[\"image\", \"segmentation\"], spatial_size=ROI_SIZE, mode = \"area\"),\n","        ScaleIntensityRanged(keys=[\"image\", \"segmentation\"],a_min=0,a_max=255,b_min=0.0,b_max=1.0,clip=True), # riscala i valori all'interno dell'immagine e della segmentazione dal range 0-255 al range 0-1\n","        AdjustContrastd(keys = ['image'], gamma = 1.5),\n","        AsDiscreted(keys=[\"segmentation\"],threshold=0.5), # porta la segmentazione in formato binario con soglia 0.5 (abbiamo modificato il range di valori nella trasformazione precedente)\n","        Zoomd(keys=[\"image\",\"segmentation\"],zoom=1.3, mode =['area', 'nearest']),\n","        KSpaceSpikeNoised(keys=[\"image\"], loc=[100,100], k_intensity=13),\n","        ToTensord(keys=[\"image\", \"segmentation\"])])"],"metadata":{"id":"H2a4RXCV07Gq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# applicazione delle trasformazioni e creazione data loader\n","train_ds_0 = Dataset(data = training_data , transform = train_transforms_0)\n","train_ds_1 = Dataset(data = training_augm_data[0:round(len(training_augm_data)*0.33)] , transform = train_transforms_1)\n","train_ds_2 = Dataset(data = training_augm_data[round(len(training_augm_data)*0.33):round(len(training_augm_data)*0.66)] , transform = train_transforms_2)\n","train_ds_3 = Dataset(data = training_augm_data[round(len(training_augm_data)*0.66):round(len(training_augm_data))] , transform = train_transforms_3)\n","ConcatDataSet_t1 = torch.utils.data.ConcatDataset([train_ds_0,train_ds_1,train_ds_2,train_ds_3])\n","train_loader_t1 = DataLoader(ConcatDataSet_t1, batch_size = BATCH_SIZE, num_workers=wks, pin_memory=True)"],"metadata":{"id":"reMsBYGZ0_J0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prova di funzionamento\n","test_patient = first(train_loader_t1)\n","a = test_patient['image']\n","b = a.permute(2,3,0,1)\n","c = np.squeeze(b)\n","plt.imshow(c[:,:,15,0])\n","print(c.shape)\n","print(a.shape)"],"metadata":{"id":"fw6AD-Bu1BK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#VALIDATION: TRASFORMAZIONI, DATASET e DATALOADER\n","#rumore rotazione, randomflip\n","val_transforms = Compose(\n","       [LoadImaged(keys=[\"image\",\"segmentation\"],image_only=False,reader=PILReader(), flag = 'gray'), # caricamento dell'immagine\n","        AsChannelFirstd(keys=[\"image\"]), # portare l'immagine nel formato channel-first (canali, dimensione 0, dimensione 1)\n","        AddChanneld(keys=[\"segmentation\"]),\n","        Resized(keys=[\"image\", \"segmentation\"], spatial_size=ROI_SIZE, mode = \"area\"),\n","        ScaleIntensityRanged(keys=[\"image\", \"segmentation\"],a_min=0,a_max=255,b_min=0.0,b_max=1.0,clip=True), # riscala i valori all'interno dell'immagine e della segmentazione dal range 0-255 al range 0-1\n","        AdjustContrastd(keys = ['image'], gamma = 1.5),\n","        AsDiscreted(keys=[\"segmentation\"],threshold=0.5), # porta la segmentazione in formato binario con soglia 0.5 (abbiamo modificato il range di valori nella trasformazione precedente)\n","        ToTensord(keys=[\"image\", \"segmentation\"])])\n","\n","val_ds = Dataset(data = validation_data , transform = val_transforms)\n","val_loader = DataLoader(val_ds, batch_size = BATCH_SIZE, num_workers=wks, pin_memory=True)"],"metadata":{"id":"PvszMgyO1C_6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#prova: Verifica Funzionamento Loader del Training Set -----\n","test_val_patient = first(val_loader)\n","a = test_val_patient['image']\n","b = a.permute(2,3,0,1)\n","c = np.squeeze(b)\n","plt.imshow(c[:,:,2,0])\n","print(c.shape)"],"metadata":{"id":"czv-DchD1FVC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creazione rete\n","\n","max_epochs = 70 # numero epoche\n","# Definiamo il device da utilizzare: GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","'''\n","model = UNet(\n","    spatial_dims=2,\n","    in_channels=3,\n","    out_channels=1,\n","    channels=(16, 32, 64, 128, 256),\n","    strides=(2, 2, 2, 2, 2),\n","    num_res_units=2,\n","    norm=Norm.BATCH,\n",").to(device)\n","'''\n","\n","# definizione parametri rete\n","device = torch.device(\"cuda:0\")\n","model = SegResNet(\n","    spatial_dims = 2,           # dimensione input (immagine 2D in questo caso)\n","    blocks_down=[1, 2, 2, 4],   # numero di blocchi di downsample per ogni layer\n","    blocks_up=[1, 1, 1],        # numero di sample block per ogni layer\n","    init_filters=16,            # numero di canali di output per il layer convoluzionale iniziale\n","    in_channels=3,              # canali in ingresso (\"RGB\" --> 3)\n","    out_channels=1,             # canali in uscita (immagine binaria)\n","    dropout_prob=0.3,           # probabilità per un elemento di essere azzerato\n",").to(device)\n","\n","# Definizione del tipo di Inferenza da applicare con il modello allenato:\n","inferer = SimpleInferer()\n","\n","# Definizione un seed per renderere ripetibili tutte le opearazioni che andiamo ad effettuare:\n","set_determinism(seed=46)\n","\n","# Definizione della loss function\n","loss_function = torch.nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n","lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n","torch.backends.cudnn.benchmark = True\n","\n","# Definizione delle trasformazioni MONAI di post-processing\n","post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.6)])\n","post_label = Compose([EnsureType(), AsDiscrete(threshod=0.5)])"],"metadata":{"id":"YPw_WoNe1HCx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#CREAZIONE CARTELLA DI DESTINAZIONE DEGLI OUTPUT\n","current_dir = '/content/drive/MyDrive/Colab Notebooks/DEF_ 3DMRI Challenge'\n","testFd = os.path.join(current_dir,'OUTPUTS_29_01_23t1_rgb')\n","if not os.path.isdir(testFd):\n","    os.mkdir(testFd)"],"metadata":{"id":"CfBi5XQy1Koy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Allenamento rete"],"metadata":{"id":"Clqtv0xv1M3b"}},{"cell_type":"code","source":["# funzione train che viene richiamata durante l'allenamento della rete\n","\n","def train(global_step, train_loader, dice_val_best, global_step_best):\n","    model.train() # setta il modello in modalità training\n","    epoch_loss = 0\n","    step = 0\n","\n","    epoch_iterator = tqdm(train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True) # crea un oggetto tqdm per tracciare l'avenzamento delle epoche\n","\n","    for step, batch in enumerate(epoch_iterator): # ad ogni ciclo for estrae una coppia step (numero dell'iterazione), batch (immagine e segmentazione) dal train loader\n","        step += 1\n","        x, y = (batch[\"image\"].cuda(), batch[\"segmentation\"].cuda()) # manda i tensori di immagine e maschera alla GPU\n","\n","        optimizer.zero_grad() # resetta i gradienti dell'optimizer\n","\n","        logit_map = model(x).sigmoid() # applica una sgimoide all'output della rete\n","\n","        loss = loss_function(logit_map, y) # calcolo della BCE loss\n","        loss.backward() # effettua la backpropagation della loss\n","        lr_scheduler.step()\n","        epoch_loss += loss.item() # accumula i valori delle loss nei vari batch\n","        optimizer.step() # calcola i gradienti e aggiorna l'optimizer\n","\n","        epoch_iterator.set_description(\"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss)) # aggiorna il counter tqdm\n","\n","        if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations: # condizione per effettuare la validazione\n","\n","            epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X Steps) (dice=X.X)\", dynamic_ncols=True)\n","            GB = global_step\n","            dice_val = validation(epoch_iterator_val,GB) # richiama la funzione di validazione per estrarre la metrica da valutare sul test set\n","            epoch_loss /= step # divide la loss in base al numero del batch\n","            epoch_loss_values.append(epoch_loss) # salva i valori della loss\n","            metric_values.append(dice_val) # salva i valori della metrica\n","\n","            # salvataggio del modello se la metrica di validazione è migliorata\n","            if dice_val > dice_val_best:\n","                dice_val_best = dice_val\n","                global_step_best = global_step\n","                torch.save( model.state_dict(), os.path.join(current_dir, \"best_metric_model.pth\"))\n","                print(\"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(dice_val_best, dice_val))\n","            else:\n","                print(\"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(dice_val_best, dice_val))\n","\n","        global_step += 1\n","\n","    return global_step, dice_val_best, global_step_best"],"metadata":{"id":"NcolOJlq1OsS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# funzione validation che viene richiamata durante l'allenamento\n","\n","def validation(epoch_iterator_val, GB):\n","    model.eval() # setta il modello in moadlità inference\n","    dice_vals = list()\n","    epoch_val_loss = 0\n","\n","    with torch.no_grad():\n","        for step, batch in enumerate(epoch_iterator_val):\n","\n","            val_inputs, val_labels = (batch[\"image\"].to(device),batch[\"segmentation\"].to(device))\n","\n","\n","            val_outputs = inferer(val_inputs, model) # applica il modello all'input\n","\n","\n","            val_inputs = val_inputs.permute(0,3,2,1)\n","\n","            loss_val = loss_function(val_outputs.sigmoid(), val_labels)\n","            epoch_val_loss += loss_val.item()\n","\n","            val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n","            val_labels  = [post_label(i) for i in decollate_batch(val_labels)]\n","\n","            dice_metric(y_pred=val_outputs, y=val_labels)\n","\n","            dice = dice_metric.aggregate().item()\n","            dice_vals.append(dice)\n","\n","            epoch_iterator_val.set_description(\"Validate (%d Steps) (dice=%2.5f)\" % (step, dice))\n","\n","            fdName = str.split(batch['image_meta_dict']['filename_or_obj'][0],'/')[-1][:-4]\n","            fd_num = str.split(batch['image_meta_dict']['filename_or_obj'][0],'/')[4]\n","            fetta = str.split(batch['image_meta_dict']['filename_or_obj'][0],'/')[6]\n","\n","            stepFd = os.path.join(testFd, str(GB))\n","\n","            if not os.path.isdir(stepFd):\n","                os.mkdir(stepFd)\n","\n","            val_outputs = val_outputs[0][0].detach().cpu().numpy()*255\n","\n","            dim = ROI_SIZE\n","            testFd_1 = os.path.join(stepFd,fd_num)\n","            if not os.path.isdir(testFd_1):\n","              os.mkdir(testFd_1)\n","\n","\n","            val_labels = val_labels[0][0].detach().cpu().numpy().squeeze()*255\n","            val_inputs = val_inputs[0].detach().cpu().numpy().squeeze()*255\n","\n","            val_inputs = np.flipud(val_inputs.astype(np.uint8))\n","            val_outputs = rotate(val_outputs,90).astype(np.uint8) # MONAI rotates output and labels\n","            val_labels = rotate(val_labels,90).astype(np.uint8)\n","\n","            pr_mask = np.expand_dims(val_outputs, axis=2)\n","            rgb_muscle_pred = np.concatenate((pr_mask, pr_mask, pr_mask), axis=2)\n","\n","            gt_mask = np.expand_dims(val_labels, axis=2)\n","            rgb_muscle_gt = np.concatenate((gt_mask, gt_mask, gt_mask), axis=2)\n","\n","            stack = np.concatenate((val_inputs, rgb_muscle_gt,rgb_muscle_pred), axis=1).astype(np.uint8)\n","\n","            stackPIL = PIL.Image.fromarray(stack)\n","            stackPIL.save(os.path.join(testFd_1,'{}.png'.format(fetta)))\n","        dice_metric.reset()\n","        epoch_val_loss /= step + 1\n","        epoch_val_loss_values.append(epoch_val_loss)\n","\n","    mean_dice_val = np.mean(dice_vals)\n","\n","    return mean_dice_val"],"metadata":{"id":"GyYTtjxC1RKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = len(train_ds_0.data) + len(train_ds_1.data) + len(train_ds_2.data) + len(train_ds_3.data)\n","#viene conteggiata un'epoca quando (batch_size * number_iteration) > = number_data\n","eval_num = int(data/BATCH_SIZE)+1\n","max_iterations = int(max_epochs * eval_num)\n","\n","\n","print(data)\n","print(max_epochs)\n","print(max_iterations)\n","print(eval_num)\n","\n","\n","dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n","global_step = 0\n","dice_val_best = 0\n","global_step_best = 0\n","epoch_loss_values = []\n","epoch_val_loss_values = []\n","metric_values = []"],"metadata":{"id":"9BVI6lRT1Tpl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while global_step < max_iterations:\n","    global_step, dice_val_best, global_step_best = train(global_step, train_loader_t1, dice_val_best, global_step_best)"],"metadata":{"id":"THYy_yMM1V3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# grafici utili: andamento del DICE e della loss in funzione delle epoche\n","# (nel grafico, nelle ascisse figura il numero di step); andamento della\n","plt.figure(\"train\", (12, 6))\n","plt.subplot(1, 2, 1)\n","plt.title(\"Iteration Average Loss\")\n","x = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n","y = epoch_loss_values\n","y1 = epoch_val_loss_values\n","plt.xlabel(\"Iteration\")\n","plt.plot(x, y,label=\"train BCE\")\n","plt.plot(x,y1,label=\"val BCE\")\n","plt.legend(loc=\"upper right\")\n","plt.subplot(1, 2, 2)\n","plt.title(\"Val Mean Dice\")\n","x = [eval_num * (i + 1) for i in range(len(metric_values))]\n","y = metric_values\n","plt.xlabel(\"Iteration\")\n","plt.plot(x, y,color='orange',label=\"val Dice\")\n","plt.legend(loc=\"upper left\")\n","\n","plt.show()"],"metadata":{"id":"F8fvs0mC1a0I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test della rete (su test set)"],"metadata":{"id":"wy0y245f1c2k"}},{"cell_type":"code","source":["current_dir = '/content/drive/MyDrive/Colab Notebooks/3DMRI Challenge'\n","#definizione rete\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","'''\n","model = UNet(\n","    spatial_dims=2,\n","    in_channels=3,\n","    out_channels=1,\n","    channels=(16, 32, 64, 128, 256),\n","    strides=(2, 2, 2, 2, 2),\n","    num_res_units=2,\n","    norm=Norm.BATCH,\n",").to(device)\n","'''\n","\n","device = torch.device(\"cuda:0\")\n","model = SegResNet(\n","    spatial_dims = 2,\n","    blocks_down=[1, 2, 2, 4],\n","    blocks_up=[1, 1, 1],\n","    init_filters=16,\n","    in_channels=3,\n","    out_channels=1,\n","    dropout_prob=0.3,\n",").to(device)\n","\n","#CARICAMENTO DEL MODELLO\n","model.load_state_dict(torch.load(current_dir + \"SegResNet2.pth\"))\n","inferer = SimpleInferer()\n","\n","torch.backends.cudnn.benchmark = True\n","\n","dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n"],"metadata":{"id":"79xVUqih1e75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Trasformazioni del test set\n","\n","test_transforms_0 = Compose(\n","       [LoadImaged(keys=[\"image\",\"segmentation\"],image_only=False,reader=PILReader(), flag = 'gray'), # caricamento dell'immagine\n","        AsChannelFirstd(keys=[\"image\"]),\n","        AddChanneld(keys=[\"segmentation\"]),\n","        Resized(keys=[\"image\", \"segmentation\"], spatial_size=ROI_SIZE, mode = \"area\"),\n","        ScaleIntensityRanged(keys=[\"image\", \"segmentation\"],a_min=0,a_max=255,b_min=0.0,b_max=1.0,clip=True), # riscala i valori all'interno dell'immagine e della segmentazione dal range 0-255 al range 0-1\n","        AdjustContrastd(keys = ['image'], gamma = 1.5),\n","        AsDiscreted(keys=[\"segmentation\"],threshold=0.5), # porta la segmentazione in formato binario con soglia 0.5 (abbiamo modificato il range di valori nella trasformazione precedente),\n","        ToTensord(keys=[\"image\", \"segmentation\"])])\n","\n","test_ds = IterableDataset(data = test_data, transform = test_transforms_0)\n","test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=wks, pin_memory=True)\n","\n","model.eval()\n","dice_tests = list()\n","epoch_test_loss = 0\n","epoch_test_loss_values = []\n","min_number_of_pixel = 2000\n","FP_tot = list()\n","n_of_pixel = list()\n","TP_tot = list()\n","with torch.no_grad():\n","    for step, batch in enumerate(test_loader):\n","\n","        test_inputs, test_labels = (batch[\"image\"].to(device),batch[\"segmentation\"].to(device))\n","\n","        test_outputs = inferer(test_inputs, model)\n","\n","        test_inputs = test_inputs.permute(0,3,2,1)\n","\n","        loss_test = loss_function(test_outputs.sigmoid(), test_labels)\n","        epoch_test_loss += loss_test.item()\n","\n","        test_outputs = [post_pred(i) for i in decollate_batch(test_outputs)]\n","        test_labels  = [post_label(i) for i in decollate_batch(test_labels)]\n","\n","        # compute metric for current iteration\n","        dice_metric(y_pred=test_outputs, y=test_labels)\n","\n","        dice = dice_metric.aggregate().item()\n","        dice_tests.append(dice)\n","\n","        testFd = os.path.join(current_dir,'TESTING')\n","\n","        if not os.path.isdir(testFd):\n","            os.mkdir(testFd)\n","        maskFd = os.path.join(current_dir,'TESTING','NET_MASK')\n","        if not os.path.isdir(maskFd):\n","          os.mkdir(maskFd)\n","\n","        for jj in range(test_inputs.shape[0]):\n","          stepFd = os.path.join(testFd, str(jj))\n","          fdName = str.split(batch['image_meta_dict']['filename_or_obj'][jj],'/')[-1][:-4]\n","          flag = 0\n","          test_inputs_slice = test_inputs[jj].detach().cpu().numpy().squeeze()*255\n","          test_inputs_slice = transform.resize(test_inputs_slice,(240,240))\n","          test_inputs_slice = np.array(test_inputs_slice, dtype=np.uint8)\n","          # Estrai i canali R, G, B dell'immagine\n","          r, g, b = test_inputs_slice[:, :, 0], test_inputs_slice[:, :, 1], test_inputs_slice[:, :, 2]\n","          non_zero_pixels_r = np.sum(r != 0)\n","          non_zero_pixels_g = np.sum(g != 0)\n","          non_zero_pixels_b = np.sum(b != 0)\n","          non_zero_pixels = np.max(np.array([non_zero_pixels_r,non_zero_pixels_g,non_zero_pixels_b]))\n","          if non_zero_pixels < min_number_of_pixel:\n","            flag = 1\n","\n","          # operazioni di post processing\n","          test_outputs_slice = test_outputs[jj][0].detach().cpu().numpy().squeeze()*255\n","          test_outputs_slice = transform.resize(test_outputs_slice,(240,240))\n","          test_outputs_slice = rotate(test_outputs_slice,90).astype(np.uint8)\n","          test_outputs_slice = binary_fill_holes(test_outputs_slice)  # riempimento buchi\n","          test_outputs_slice = np.flipud(test_outputs_slice.astype(np.uint8))\n","          if flag == 0: # l'oggetto nell'immagine è sufficientemente grande\n","            test_outputs_slice = np.where(test_outputs_slice==1,255,0)\n","          if flag == 1: #  l'oggetto nell'immagine è troppo piccolo per una segmentazione corretta\n","            test_outputs_slice = np.where(test_outputs_slice==1,0,0) # la segmentazione automatica viene posta uguale a 0\n","\n","          test_outputs_slice = np.array(test_outputs_slice, dtype=np.uint8)\n","          test_outputs_slice = np.expand_dims(test_outputs_slice, axis=2)\n","          test_outputs_slice = np.concatenate((test_outputs_slice,test_outputs_slice,test_outputs_slice), axis=2)\n","\n","          test_labels_slice = test_labels[jj][0].detach().cpu().numpy().squeeze()*255\n","          test_labels_slice = transform.resize(test_labels_slice,(240,240))\n","          test_labels_slice = rotate(test_labels_slice,90).astype(np.uint8)\n","          test_labels_slice = np.flipud(test_labels_slice.astype(np.uint8))\n","          test_labels_slice = np.array(test_labels_slice, dtype=np.uint8)\n","          test_labels_slice = np.expand_dims(test_labels_slice, axis=2)\n","          test_labels_slice = np.concatenate((test_labels_slice,test_labels_slice,test_labels_slice), axis=2)\n","\n","          FP = len(np.where((test_labels_slice==0)&(test_outputs_slice==255))[0])\n","          FP_tot.append(FP)\n","          TP = len(np.where((test_labels_slice==255)&(test_outputs_slice==255))[0])\n","          TP_tot.append(TP)\n","          n_of_pixel.append(non_zero_pixels)\n","\n","          pz_path = os.path.join(testFd,str.split(batch['image_meta_dict']['filename_or_obj'][jj],'/')[4])\n","          if not os.path.isdir(pz_path):\n","            os.mkdir(pz_path)\n","          stack = np.concatenate((test_inputs_slice, test_labels_slice, test_outputs_slice), axis=1).astype(np.uint8)\n","          stackPIL = PIL.Image.fromarray(stack)\n","          stackPIL.save(os.path.join(pz_path,'{}.png'.format(fdName)))\n","          #salvataggio maschere di output in una cartella separatata per il calcolo successivo delle metriche\n","          maskFd = os.path.join(current_dir,'TESTING','NET_MASK',str.split(batch['image_meta_dict']['filename_or_obj'][jj],'/')[4])\n","          if not os.path.isdir(maskFd):\n","            os.mkdir(maskFd)\n","          maskPIL = PIL.Image.fromarray(test_outputs_slice)\n","          maskPIL.save(os.path.join(maskFd,'{}.png'.format(fdName)))\n","\n","    dice_metric.reset()\n","    epoch_test_loss /= step + 1\n","    epoch_test_loss_values.append(epoch_test_loss)\n","\n","mean_dice_test = np.mean(dice_tests)\n","error_dice_test = np.std(dice_tests)\n","errore_sulla_media = np.std(dice_tests) / np.sqrt(len(dice_tests))\n","print(\"{:.3f} +/- {:.3f}\".format(mean_dice_test, error_dice_test))\n","print(\"errore sulla media: {:.3f}\".format(errore_sulla_media))"],"metadata":{"id":"yFbHguBu1k-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Grafico per dimostrare l'elevato numero di falsi positivi sotto una certa dimensione\n","# degli oggetti nelle immagini\n","vec1 = np.array(n_of_pixel)\n","vec2 = np.array(FP_tot)\n","vec3 = np.array(TP_tot)\n","indici = np.where(vec1<7000)\n","plt.scatter(vec1[indici[0]], vec2[indici[0]], label= \"stars\", color= \"magenta\",\n","            marker= \"*\", s=30)\n","plt.scatter(vec1[indici[0]], vec3[indici[0]], label= \"stars\", color= \"green\",\n","            marker= \"*\", s=30)\n","plt.axvline(2000, color='r', linestyle='-')\n","plt.xlabel(\"Area Encefalo\")\n","plt.ylabel(\"Pixel Falsi Positivi\")\n","plt.xlim(0, 7000)\n","plt.ylim(0, 6000)\n","plt.show()"],"metadata":{"id":"mQ1_Qt6l1nRw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ricostruzione dei volumi 3D\n","\n","main = '/content'\n","dataFolder_original = os.path.join(main, 'DATASET','VOLUMES','TRAIN')\n","dataFolder = '/content/drive/MyDrive/Colab Notebooks/DEF_ 3DMRI Challenge/TESTING/NET_MASK'\n","outputFolder = '/content/drive/MyDrive/Colab Notebooks/DEF_ 3DMRI Challenge/ricostruzione_volumi_output'\n","\n","if not os.path.isdir(outputFolder):\n","      os.mkdir(outputFolder) # creazione cartella output\n","\n","volumesList = os.listdir(dataFolder) # lista dei volumi da ricostruire a partire dalle segmentazioni automatiche presenti in dataFolder\n","\n","for i in tqdm(volumesList):\n","    slices = []\n","    subjectFolder = os.path.join(dataFolder, i)\n","    subjectOuputFolder = os.path.join(outputFolder, i)\n","\n","    if not os.path.isdir(subjectOuputFolder):\n","      os.mkdir(subjectOuputFolder)\n","\n","    if not '.DS_Store' in subjectFolder:\n","\n","        files = [x for x in os.listdir(subjectFolder)]\n","\n","        for j in np.sort(files):\n","          img = sitk.ReadImage(os.path.join(subjectFolder,j)) #caricamento segmentazioni\n","          img_vol = sitk.GetArrayFromImage(img).astype(np.uint8)>0\n","          tempSlice = img_vol[:,:,0].astype(np.uint8)*255\n","          slices.append(np.array(tempSlice))\n","          inputVolume = np.stack(slices, axis=-1)\n","\n","        inputVolume = inputVolume/np.max(inputVolume)*255\n","        inputVolume = inputVolume.astype(np.uint8)\n","        numpyVolume_tens = torch.FloatTensor(inputVolume)\n","        numpyVolume_tens = numpyVolume_tens.permute(2,0,1)\n","        newVolume = sitk.GetImageFromArray(numpyVolume_tens) # l'array di numeri ottenuto dalla concatenazione delle slice viene trasformato\n","              # in formato immagine in modo da poter essere comparato con il volume originale che viene letto di seguito nella cartella\n","              # di origine\n","\n","        orginal_volume = os.path.join(dataFolder_original,i) # lettura del volume originale per l'estrazione delle informazioni spaziali di ogni slice\n","        original_volume_list = os.listdir(orginal_volume)[0]\n","        path_orig_vol = os.path.join(orginal_volume,original_volume_list)\n","        inputVolume_orig = sitk.ReadImage(path_orig_vol)\n","        numpyVolume_orig = sitk.GetArrayFromImage(inputVolume_orig).astype(np.uint8)>0\n","\n","        newVolume.CopyInformation(inputVolume_orig) # le informazioni spaziali vengono trasferite supponendo che le slices siano state nominate durante tutto\n","            # il processo in egual modo rispetto a come sono state estratte inizialmente\n","        out = os.path.join(subjectOuputFolder,'volume_output_' + i + '.nii')\n","        sitk.WriteImage(newVolume, out) # salvataggio in formato nifti (.nii)"],"metadata":{"id":"PmC9EeD-1pUI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# funzione per il calcolo del Jaccard Index\n","def jaccard_index(image1, image2):\n","    set1 = set(np.ravel(image1))\n","    set2 = set(np.ravel(image2))\n","    jaccard_index = len(set1 & set2) / len(set1 | set2)\n","    return jaccard_index"],"metadata":{"id":"oUJOuMwX1rFS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# funzione per il calcolo della Hausdorff Distance al 95esimo percentile\n","def HD95(image1, image2):\n","  nonzero_indices1 = np.nonzero(image1)\n","  nonzero_indices2 = np.nonzero(image2)\n","  nonzero_coords1 = np.column_stack(nonzero_indices1)\n","  nonzero_coords2 = np.column_stack(nonzero_indices2)\n","  eucl = distance.cdist(nonzero_coords1, nonzero_coords2, 'euclidean')\n","  minimiA = np.min(eucl, axis=1)\n","  minimiB = np.min(eucl, axis=0)\n","  percentile = 95\n","  resultA = np.percentile(minimiA, percentile, interpolation='nearest') #qui dobbiamo decidere se nearest o default, secondo me è nearest\n","  resultB = np.percentile(minimiB, percentile, interpolation='nearest')\n","  Hausdorff_distance_95 = np.max([resultA, resultB])\n","  return Hausdorff_distance_95"],"metadata":{"id":"_iVC_8bq1str"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sezione per il calcolo delle metriche\n","\n","pz_dir = os.listdir(\"/content/drive/MyDrive/Colab Notebooks/3DMRI Challenge/TESTING/NET_MASK\")\n","tot_dice = list()\n","errore_area = list()\n","tot_jaccard = list()\n","tot_hausdorff = list()\n","\n","for i in pz_dir:\n","  pz_path_out = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/3DMRI Challenge/TESTING/NET_MASK\",i)\n","  pz_path_in = os.path.join(\"/content/DATASET/SLICES\",i,\"seg\")\n","  segmentation_list = os.listdir(pz_path_out)\n","  for t in segmentation_list:\n","    seg_path_out = os.path.join(pz_path_out,t)\n","    seg_path_in = os.path.join(pz_path_in,t)\n","    seg_out = cv2.imread(seg_path_out)[:,:,0]\n","    seg_in = cv2.imread(seg_path_in)[:,:,0]\n","    # DICE\n","    TP = len(np.where((seg_in==255)&(seg_out==255))[0])\n","    FP = len(np.where((seg_in==0)&(seg_out==255))[0])\n","    FN = len(np.where((seg_in==255)&(seg_out==0))[0])\n","    if (2*TP+FP+FN) == 0:\n","      dice = 1\n","      tot_dice.append(dice)\n","    else:\n","      dice = (2*TP)/(2*TP+FP+FN)\n","      tot_dice.append(dice)\n","    # DIFFERENZA DI AREE\n","    seg_out = np.where(seg_out==255,1,0)\n","    seg_in = np.where(seg_in==255,1,0)\n","    area_out = np.sum(seg_out)\n","    area_in = np.sum(seg_in)\n","    diff_area = area_out - area_in\n","    errore_area.append(diff_area)\n","    # JACCARD INDEX\n","    j_ind = jaccard_index(seg_out,seg_in)\n","    tot_jaccard.append(j_ind)\n","    # HAUSDORFF DISTANCE 95%\n","    nonzero_indices1 = np.nonzero(seg_in)\n","    nonzero_indices2 = np.nonzero(seg_out)\n","    if ((len(nonzero_indices1[0])!=0) and (len(nonzero_indices2[0])!=0)):\n","      hausdorff_distance = HD95(seg_in, seg_out)\n","      tot_hausdorff.append(hausdorff_distance)\n","\n","\n","media_dice = np.mean(tot_dice)\n","errore_dice = np.std([x for x in tot_dice if x != 0 and x != 1])\n","print(\"DICE = {:.3f}+/-{:.3f}\".format(media_dice, errore_dice))\n","print(\"ERRORE AREA MAX = {:.0f}\".format(np.max(errore_area)))\n","print(\"ERRORE AREA MIN = {:.0f}\".format(np.min(errore_area)))\n","print(\"ERRORE AREA MEDIO = {:.0f}\".format(int(np.mean(errore_area))))\n","media_jaccard = np.mean(tot_jaccard)\n","errore_jaccard = np.std(tot_jaccard)\n","print(\"JACCARD = {:.3f}+/-{:.3f}\".format(media_jaccard, errore_jaccard))\n","media_hausdorff = np.mean(tot_hausdorff)\n","errore_hausdorff = np.std(tot_hausdorff)\n","print(\"HAUSDORFF = {:.3f}+/-{:.3f}\".format(media_hausdorff, errore_hausdorff))"],"metadata":{"id":"58plCUT11vrM"},"execution_count":null,"outputs":[]}]}